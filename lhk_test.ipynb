{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b18fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a901c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'yolov5su.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17.7M/17.7M [00:01<00:00, 11.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D 칼만 필터 기반 추적 시스템을 시작합니다. 목표 인원수: 4명\n",
      "프레임 1: 댄서 슬롯 0 초기화.\n",
      "프레임 1: 댄서 슬롯 1 초기화.\n",
      "프레임 1: 댄서 슬롯 2 초기화.\n",
      "프레임 1: 댄서 슬롯 3 초기화.\n",
      "처리 완료! 최종 결과가 'aespa_testtest_output.mp4'와 'aespa_testtest_skeletons_data.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# mediapipe 라이브러리를 사용하여 기본 스켈레톤 추출\n",
    "# YOLO 라이브러리를 사용하여, 다중 객체 탐지 (Top_down 방식)\n",
    "# 칼만 필터(Kalman Filter)를 사용하여, 각 관절의 다음 위치를 예측하고 보정하여 성능 개선\n",
    "# 상태 예측 및 보간: 추적을 잠시 놓친 스켈레톤의 위치를 예측하여, 시각적 끊김 없이 보이도록 처리\n",
    "# 슬롯 기반 할당(Slot-Based Assignment)' 개념을 도입하여 성능 향상\n",
    "# 헝가리안 알고리즘(scipy.linear_sum_assignment)을 사용:\n",
    "# - 매 프레임마다 새로 탐지된 사람들과 기존 '댄서 슬롯'들의 위치를 비교하여, 전체적으로 가장 거리가 가까운 최적의 짝을 확인\n",
    "# 3D 칼만 필터: 개별 댄서의 물리적 움직임을 3차원 공간에서 부드럽고 정확하게 예측\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "from collections import Counter\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ----------------------------------\n",
    "# 1. 클래스 및 함수 정의\n",
    "# ----------------------------------\n",
    "class KalmanFilter3D:\n",
    "    \"\"\"A simple Kalman filter for 3D point tracking.\"\"\"\n",
    "    def __init__(self, dt=1, std_acc=1, x_std_meas=0.1, y_std_meas=0.1, z_std_meas=0.1):\n",
    "        self.state = np.zeros((6, 1))   # 상태 변수를 6차원으로 확장: [x, y, z, vx, vy, vz]\n",
    "        # 상태 전이 행렬을 6x6으로 확장\n",
    "        self.F = np.array([[1,0,0,dt,0,0], [0,1,0,0,dt,0], [0,0,1,0,0,dt],\n",
    "                           [0,0,0,1,0,0], [0,0,0,0,1,0], [0,0,0,0,0,1]])\n",
    "        # 측정 행렬을 3x6으로 확장\n",
    "        self.H = np.array([[1,0,0,0,0,0], [0,1,0,0,0,0], [0,0,1,0,0,0]])\n",
    "        self.Q = np.eye(6)*std_acc**2\n",
    "        self.R = np.diag([x_std_meas**2, y_std_meas**2, z_std_meas**2])\n",
    "        self.P = np.eye(6)\n",
    "    def predict(self):\n",
    "        self.state = np.dot(self.F, self.state)\n",
    "        self.P = np.dot(np.dot(self.F, self.P), self.F.T) + self.Q\n",
    "        return self.state\n",
    "    def update(self, z):\n",
    "        # 입력 z는 이제 3D 벡터 [x, y, z]\n",
    "        S = np.dot(self.H, np.dot(self.P, self.H.T)) + self.R\n",
    "        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S))\n",
    "        self.state += np.dot(K, (z - np.dot(self.H, self.state)))\n",
    "        self.P -= np.dot(np.dot(K, self.H), self.P)\n",
    "        return self.state\n",
    "\n",
    "class DancerSlot:\n",
    "    \"\"\"영구적인 댄서 슬롯의 모든 데이터를 저장하는 클래스\"\"\"\n",
    "    def __init__(self, slot_id, initial_bbox):\n",
    "        self.id = slot_id\n",
    "        self.kalman_filters = [KalmanFilter3D() for _ in range(33)]\n",
    "        self.landmarks = np.zeros((33, 4))\n",
    "        self.bbox = initial_bbox\n",
    "        self.disappeared_frames = 0\n",
    "        self.is_active = True\n",
    "        self.color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "    def reinitialize_kalman_filters(self):\n",
    "        \"\"\"칼만 필터를 초기 상태로 리셋합니다.\"\"\"\n",
    "        self.kalman_filters = [KalmanFilter3D() for _ in range(33)]\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    \"\"\"마우스 이벤트를 처리하여 스켈레톤 위치를 수정하는 함수\"\"\"\n",
    "    global is_dragging, selected_landmark, dancer_slots, paused, swap_mode, selected_for_swap\n",
    "\n",
    "    # ID 교체 로직\n",
    "    if swap_mode and event == cv2.EVENT_LBUTTONDOWN:\n",
    "        clicked_slot_id = None\n",
    "        for slot_id, slot in dancer_slots.items():\n",
    "            if not slot.is_active: continue\n",
    "            x1, y1, x2, y2 = slot.bbox\n",
    "            if x1 < x < x2 and y1 < y < y2:\n",
    "                clicked_slot_id = slot_id\n",
    "                break\n",
    "        \n",
    "        if clicked_slot_id is not None and clicked_slot_id not in selected_for_swap:\n",
    "            selected_for_swap.append(clicked_slot_id)\n",
    "            print(f\"ID 교체를 위해 Slot {clicked_slot_id} 선택됨. ({len(selected_for_swap)}/2)\")\n",
    "\n",
    "            if len(selected_for_swap) == 2:\n",
    "                id1, id2 = selected_for_swap\n",
    "                dancer_slots[id1].id, dancer_slots[id2].id = dancer_slots[id2].id, dancer_slots[id1].id\n",
    "                dancer_slots[id1].color, dancer_slots[id2].color = dancer_slots[id2].color, dancer_slots[id1].color\n",
    "                print(f\"!!! ID 교체 완료: Slot {id1} <-> Slot {id2}\")\n",
    "                selected_for_swap = []\n",
    "                swap_mode = False\n",
    "        return\n",
    "\n",
    "    if not paused: return\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        min_dist = float('inf')\n",
    "        for slot_id, slot in dancer_slots.items():\n",
    "            if not slot.is_active: continue\n",
    "            for i, landmark in enumerate(slot.landmarks):\n",
    "                dist = np.linalg.norm(np.array([landmark[0], landmark[1]]) - np.array([x, y]))\n",
    "                if dist < 10 and dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    selected_landmark['slot_id'] = slot_id\n",
    "                    selected_landmark['landmark_idx'] = i\n",
    "                    is_dragging = True\n",
    "                    print(f\"선택됨: Slot {slot_id}, Landmark {i}\")\n",
    "                    break\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if is_dragging:\n",
    "            slot_id = selected_landmark['slot_id']\n",
    "            lm_idx = selected_landmark['landmark_idx']\n",
    "            dancer_slots[slot_id].landmarks[lm_idx, 0] = x\n",
    "            dancer_slots[slot_id].landmarks[lm_idx, 1] = y\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        if is_dragging:\n",
    "            slot_id = selected_landmark['slot_id']\n",
    "            lm_idx = selected_landmark['landmark_idx']\n",
    "            kf = dancer_slots[slot_id].kalman_filters[lm_idx]\n",
    "            kf.state[0, 0] = dancer_slots[slot_id].landmarks[lm_idx, 0]\n",
    "            kf.state[1, 0] = dancer_slots[slot_id].landmarks[lm_idx, 1]\n",
    "            print(f\"수정 완료: Slot {slot_id}, Landmark {lm_idx} 위치가 ({kf.state[0,0]:.1f}, {kf.state[1,0]:.1f})로 업데이트됨\")\n",
    "        is_dragging = False\n",
    "        selected_landmark = {'slot_id': None, 'landmark_idx': None}\n",
    "\n",
    "# ----------------------------------\n",
    "# 2. 초기 설정\n",
    "# ----------------------------------\n",
    "TARGET_PERSON_COUNT = 4\n",
    "yolo_model = YOLO('yolov8s.pt')\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)\n",
    "video_path = \"aespa_test.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "output_video_path = video_path.replace('.mp4', 'test_output.mp4')\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "csv_output_path = video_path.replace('.mp4', 'test_skeletons_data.csv')\n",
    "csv_file = open(csv_output_path, 'w', newline='', encoding='utf-8')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(['frame', 'slot_id', 'landmark_id', 'x', 'y', 'z', 'visibility', 'bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2'])\n",
    "\n",
    "dancer_slots = {}\n",
    "MAX_DISAPPEARED_FRAMES = 15\n",
    "frame_counter = 0\n",
    "\n",
    "# 추가 변수\n",
    "is_dragging = False\n",
    "selected_landmark = {'slot_id': None, 'landmark_idx': None}\n",
    "paused = False\n",
    "swap_mode = False\n",
    "selected_for_swap = []\n",
    "\n",
    "print(f\"3D 칼만 필터 기반 추적 시스템을 시작합니다. 목표 인원수: {TARGET_PERSON_COUNT}명\")\n",
    "\n",
    "# ----------------------------------\n",
    "# 3. 메인 루프: 프레임별 처리\n",
    "# ----------------------------------\n",
    "while cap.isOpened():\n",
    "    if not paused:\n",
    "\n",
    "        success, frame = cap.read()\n",
    "        if not success: break\n",
    "\n",
    "        # STEP 1: YOLO로 모든 사람 '탐지' (track 대신 predict 사용)\n",
    "        results = yolo_model.predict(frame, classes=[0], conf=0.4, verbose=False)\n",
    "        detections = results[0].boxes.xyxy.cpu().numpy()\n",
    "\n",
    "        # --- 슬롯 초기화 로직 ---\n",
    "        if len(dancer_slots) < TARGET_PERSON_COUNT:\n",
    "            for i, bbox in enumerate(detections):\n",
    "                # 이미 존재하는 슬롯의 개수를 ID로 사용\n",
    "                slot_id = len(dancer_slots)\n",
    "                if slot_id < TARGET_PERSON_COUNT:\n",
    "                    print(f\"프레임 {frame_counter}: 댄서 슬롯 {slot_id} 초기화.\")\n",
    "                    dancer_slots[slot_id] = DancerSlot(slot_id, bbox)\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        # --- 슬롯 할당 로직 (매 프레임 실행) ---\n",
    "        matched_detection_indices = set()\n",
    "        if detections.shape[0] > 0 and len(dancer_slots) > 0:\n",
    "            # 1. 활성화된 슬롯과 모든 탐지 객체 간의 매칭\n",
    "            active_slots = {sid: slot for sid, slot in dancer_slots.items() if slot.is_active}\n",
    "            slot_keys = list(active_slots.keys())\n",
    "            \n",
    "            if len(slot_keys) > 0:\n",
    "                # 비용 행렬 계산\n",
    "                cost_matrix = np.zeros((len(slot_keys), len(detections)))\n",
    "                for i, slot_id in enumerate(slot_keys):\n",
    "                    slot_center = ((active_slots[slot_id].bbox[0] + active_slots[slot_id].bbox[2]) / 2, (active_slots[slot_id].bbox[1] + active_slots[slot_id].bbox[3]) / 2)\n",
    "                    for j, det_box in enumerate(detections):\n",
    "                        det_center = ((det_box[0] + det_box[2]) / 2, (det_box[1] + det_box[3]) / 2)\n",
    "                        cost_matrix[i, j] = np.linalg.norm(np.array(slot_center) - np.array(det_center))\n",
    "                \n",
    "                # 헝가리안 알고리즘으로 최적 할당\n",
    "                row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "                \n",
    "                # 할당된 슬롯 업데이트\n",
    "                for r, c in zip(row_ind, col_ind):\n",
    "                    if cost_matrix[r, c] < 250: # 너무 멀리 떨어진 매칭은 무시\n",
    "                        slot_id = slot_keys[r]\n",
    "                        person_slot = dancer_slots[slot_id]\n",
    "                        person_slot.disappeared_frames = 0\n",
    "                        person_slot.is_active = True\n",
    "                        person_slot.bbox = detections[c]\n",
    "                        matched_detection_indices.add(c)\n",
    "\n",
    "        # 2. ID 부활 로직: 비활성화된 슬롯과 매칭되지 않은 탐지 객체 간의 매칭\n",
    "        unmatched_detection_indices = list(set(range(len(detections))) - matched_detection_indices)\n",
    "        inactive_slots = {sid: slot for sid, slot in dancer_slots.items() if not slot.is_active}\n",
    "\n",
    "        if len(unmatched_detection_indices) > 0 and len(inactive_slots) > 0:\n",
    "                unmatched_detections = detections[unmatched_detection_indices]\n",
    "                inactive_slot_keys = list(inactive_slots.keys())\n",
    "\n",
    "                # 비활성 슬롯과 남은 탐지 객체 간의 실제 거리로 비용 행렬 계산\n",
    "                cost_matrix_revival = np.zeros((len(inactive_slot_keys), len(unmatched_detections)))\n",
    "                for i, slot_id in enumerate(inactive_slot_keys):\n",
    "                    # 비활성 슬롯의 마지막 예측 위치를 사용\n",
    "                    slot_center = ((inactive_slots[slot_id].bbox[0] + inactive_slots[slot_id].bbox[2]) / 2, (inactive_slots[slot_id].bbox[1] + inactive_slots[slot_id].bbox[3]) / 2)\n",
    "                    for j, det_box in enumerate(unmatched_detections):\n",
    "                        det_center = ((det_box[0] + det_box[2]) / 2, (det_box[1] + det_box[3]) / 2)\n",
    "                        cost_matrix_revival[i, j] = np.linalg.norm(np.array(slot_center) - np.array(det_center))\n",
    "\n",
    "                row_ind_rev, col_ind_rev = linear_sum_assignment(cost_matrix_revival)\n",
    "                for r, c in zip(row_ind_rev, col_ind_rev):\n",
    "                            slot_id = inactive_slot_keys[r]\n",
    "                            detection_idx = list(unmatched_detection_indices)[c]\n",
    "                            \n",
    "                            print(f\"프레임 {frame_counter}: 슬롯 {slot_id} 부활!\")\n",
    "                            person_slot = dancer_slots[slot_id]\n",
    "                            person_slot.is_active = True\n",
    "                            person_slot.disappeared_frames = 0\n",
    "                            person_slot.bbox = detections[detection_idx]\n",
    "                            person_slot.reinitialize_kalman_filters() # 칼만 필터 초기화\n",
    "                            matched_detection_indices.add(detection_idx)\n",
    "\n",
    "        # --- 3. 포즈 추정 및 상태 업데이트/예측 ---\n",
    "        for slot_id, person_slot in dancer_slots.items():\n",
    "            if not person_slot.is_active: continue\n",
    "\n",
    "            # 현재 프레임에서 업데이트된(매칭된) 슬롯인 경우\n",
    "            if person_slot.disappeared_frames == 0:\n",
    "                x1, y1, x2, y2 = [int(coord) for coord in person_slot.bbox]\n",
    "                padding = 0.15; box_w, box_h = x2 - x1, y2 - y1\n",
    "                x1_pad = max(0, int(x1 - box_w * padding)); y1_pad = max(0, int(y1 - box_h * padding))\n",
    "                x2_pad = min(frame_width, int(x2 + box_w * padding)); y2_pad = min(frame_height, int(y2 + box_h * padding))\n",
    "                person_crop = frame[y1_pad:y2_pad, x1_pad:x2_pad]\n",
    "\n",
    "                if person_crop.shape[0] > 0 and person_crop.shape[1] > 0:\n",
    "                    crop_rgb = cv2.cvtColor(person_crop, cv2.COLOR_BGR2RGB); pose_results = pose.process(crop_rgb)\n",
    "                    if pose_results.pose_landmarks and len(pose_results.pose_landmarks.landmark) == 33:\n",
    "                        crop_h, crop_w, _ = person_crop.shape\n",
    "                        for i, landmark in enumerate(pose_results.pose_landmarks.landmark):\n",
    "                            measured_x, measured_y = x1_pad + landmark.x * crop_w, y1_pad + landmark.y * crop_h\n",
    "                            measured_z = landmark.z * crop_w \n",
    "                            kf = person_slot.kalman_filters[i]\n",
    "                            if np.all(kf.state[0:3] == 0): kf.state[0], kf.state[1], kf.state[2] = measured_x, measured_y, measured_z\n",
    "                            kf.predict(); updated_state = kf.update(np.array([[measured_x], [measured_y], [measured_z]]))\n",
    "                            person_slot.landmarks[i] = [updated_state[0, 0], updated_state[1, 0], updated_state[2, 0], landmark.visibility]\n",
    "            else: # 사라진 슬롯인 경우\n",
    "                person_slot.disappeared_frames += 1\n",
    "                if person_slot.disappeared_frames > MAX_DISAPPEARED_FRAMES:\n",
    "                    print(f\"프레임 {frame_counter}: 슬롯 {slot_id} 비활성화.\")\n",
    "                    person_slot.is_active = False\n",
    "                    continue\n",
    "                \n",
    "                for i in range(33):\n",
    "                    kf = person_slot.kalman_filters[i]; predicted_state = kf.predict()\n",
    "                    person_slot.landmarks[i, 0:3] = predicted_state[0:3, 0].T\n",
    "                \n",
    "                center_x = np.mean(person_slot.landmarks[:, 0]); center_y = np.mean(person_slot.landmarks[:, 1])\n",
    "                if not (np.isnan(center_x) or np.isnan(center_y)):\n",
    "                    w, h = person_slot.bbox[2] - person_slot.bbox[0], person_slot.bbox[3] - person_slot.bbox[1]\n",
    "                    person_slot.bbox = [center_x - w/2, center_y - h/2, center_x + w/2, center_y + h/2]\n",
    "\n",
    "        # --- 4. 최종 시각화 및 데이터 저장 ---\n",
    "        for slot_id, person_slot in dancer_slots.items():\n",
    "            if not person_slot.is_active: continue\n",
    "\n",
    "            color = person_slot.color; label = f\"ID: {person_slot.id}\"\n",
    "            if person_slot.disappeared_frames > 0:\n",
    "                color = tuple(c // 2 for c in color)\n",
    "                label += \" (Lost)\"\n",
    "            x1, y1, x2, y2 = [int(c) for c in person_slot.bbox]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            \n",
    "            landmarks_to_process = person_slot.landmarks\n",
    "            bbox_for_csv = person_slot.bbox.tolist()    # 후처리를 위해 bbox 좌표도 함께 저장\n",
    "\n",
    "            for i, landmark in enumerate(landmarks_to_process):\n",
    "                csv_writer.writerow([frame_counter, person_slot.id, i, landmark[0], landmark[1], landmark[2], landmark[3]] + bbox_for_csv)\n",
    "                if landmark[3] > 0.5:\n",
    "                    cv2.circle(frame, (int(landmark[0]), int(landmark[1])), 3, color, -1)\n",
    "\n",
    "            connections = mp_pose.POSE_CONNECTIONS\n",
    "            for connection in connections:\n",
    "                start_idx, end_idx = connection\n",
    "                if landmarks_to_process[start_idx, 3] > 0.5 and landmarks_to_process[end_idx, 3] > 0.5:\n",
    "                    start_point = (int(landmarks_to_process[start_idx, 0]), int(landmarks_to_process[start_idx, 1]))\n",
    "                    end_point = (int(landmarks_to_process[end_idx, 0]), int(landmarks_to_process[end_idx, 1]))\n",
    "                    cv2.line(frame, start_point, end_point, color, 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_counter += 1\n",
    "    # cv2.imshow('Slot-Based High-Performance Tracking', frame)\n",
    "    window_name = 'Slot-Based High-Performance Tracking'\n",
    "    cv2.imshow(window_name, frame)\n",
    "    cv2.setMouseCallback(window_name, mouse_callback)\n",
    "\n",
    "    # \n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord(' '):  # 스페이스바: 일시정지/재생\n",
    "        paused = not paused\n",
    "        if paused:\n",
    "            print(\"--- 영상 일시정지 ---\")\n",
    "        else:\n",
    "            print(\"--- 영상 재생 ---\")\n",
    "            swap_mode = False # 재생 시작 시 교체 모드 해제\n",
    "            selected_for_swap = []\n",
    "            \n",
    "    elif key == ord('s'):  # 's' 키: ID 교체 모드\n",
    "        if paused:\n",
    "            swap_mode = True\n",
    "            selected_for_swap = []\n",
    "            print(\"--- ID 교체 모드 활성화: 교체할 두 사람을 클릭하세요. ---\")\n",
    "        else:\n",
    "            print(\"ID를 교체하려면 먼저 영상을 일시정지(스페이스바)하세요.\")\n",
    "\n",
    "# ----------------------------------\n",
    "# 4. 종료 처리\n",
    "# ----------------------------------\n",
    "csv_file.close(); cap.release(); out.release(); cv2.destroyAllWindows(); pose.close()\n",
    "print(f\"처리 완료! 최종 결과가 '{output_video_path}'와 '{csv_output_path}'에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca9308b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\human\\.conda\\envs\\final-project\\lib\\site-packages (3.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aefb0dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "후처리 1단계 시작: 자동화된 ID 스위치 보정 (오류 수정 최종본)\n",
      "  - 1/5: 트랙릿 분리 로직 수정 및 실행 중...\n",
      "  - 2/5: 각 트랙릿의 시작/끝 정보 수집 중...\n",
      "  - 3/5: 비디오 단일 스캔으로 모든 외모 특징 추출 중...\n",
      "  - 4/5: 트랙릿 간 연결 그래프 생성 중...\n",
      "  - 5/5: 연결 그룹 분석 및 최종 ID 할당 중...\n",
      "ID가 보정된 데이터가 'aespa_test_skeletons_postprocessed.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 후처리1\n",
    "# 트랙릿 재연결 (ID 스위치 보정): slot_id의 이동 경로를 하나의 '트랙릿(Tracklet)'으로 간주\n",
    "#    → 각 트랙릿의 특정 지점(예: 경로가 끊기기 직전, ID가 바뀐 직후)에서 **외모 특징(옷 색상)**과 **움직임 특징(위치, 속도)**을 추출\n",
    "#    → 한 트랙릿이 끝나는 지점과 다른 트랙릿이 시작하는 지점의 특징들을 비교\n",
    "#    → 만약 \"A 트랙릿의 끝과 B 트랙릿의 시작이 동일 인물일 확률이 매우 높다\"고 판단되면, 두 트랙릿을 하나로 합쳐 ID를 통일\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "\n",
    "# -- 설정 --\n",
    "# 생성된 원본 데이터 파일\n",
    "INPUT_CSV_PATH = 'aespa_testtest_skeletons_data.csv'\n",
    "\n",
    "# 원본 비디오 파일 (외모 특징 추출에 필요)\n",
    "VIDEO_PATH = 'aespa_test.mp4'\n",
    "\n",
    "# 후처리가 완료된 데이터가 저장될 파일\n",
    "OUTPUT_CSV_PATH = 'aespa_test_skeletons_postprocessed.csv'\n",
    "\n",
    "# -- 파라미터 --\n",
    "JUMP_THRESHOLD = 150  # ID 스위치를 의심할 위치 '점프' 픽셀 거리, 값이 작을 수록 더 꼼꼼하게 검사\n",
    "MAX_LINK_FRAMES = 45  # 두 트랙릿을 연결할 최대 프레임 간격\n",
    "APPEARANCE_WEIGHT = 0.7 # 외모 특징의 가중치 (0~1), 의상이 비슷하면 값을 낮추기\n",
    "MOTION_WEIGHT = 0.3     # 움직임 특징의 가중치 (0~1)\n",
    "COST_THRESHOLD = 0.65   # 연결을 위한 비용 임계값\n",
    "\n",
    "DISTANCE_GATE_THRESHOLD = 100   # 물리적 거리 제한 추가\n",
    "\n",
    "\n",
    "# --- 2. 헬퍼 함수 ---\n",
    "def get_color_histogram(frame, bbox):\n",
    "    \"\"\"지정된 바운딩 박스 영역에서 컬러 히스토그램을 계산합니다.\"\"\"\n",
    "    x1, y1, x2, y2 = [int(c) for c in bbox]\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    if roi.size == 0: return None\n",
    "    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 180])\n",
    "    cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)\n",
    "    return hist.flatten()\n",
    "\n",
    "# --- 3. 메인 후처리 로직 ---\n",
    "def relink_switched_ids_final_corrected(csv_path, video_path, output_path):\n",
    "    start_time = time.time()\n",
    "    print(\"후처리 1단계 시작: 자동화된 ID 스위치 보정 (오류 수정 최종본)\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # 💡 [오류 수정] 1. 올바른 트랙릿 분리 로직\n",
    "    print(\"  - 1/5: 트랙릿 분리 로직 수정 및 실행 중...\")\n",
    "    df['tracklet_id'] = -1\n",
    "    tracklet_counter = 0\n",
    "    \n",
    "    # 원본 slot_id별로 순회\n",
    "    for slot_id in df['slot_id'].unique():\n",
    "        person_df = df[df['slot_id'] == slot_id].sort_values(by='frame')\n",
    "        if person_df.empty: continue\n",
    "\n",
    "        # 코(landmark_id=0)의 위치를 기준으로 점프가 일어나는 '프레임 번호'를 찾음\n",
    "        nose_df = person_df[person_df['landmark_id'] == 0]\n",
    "        if len(nose_df) < 2:\n",
    "            # 트랙릿이 너무 짧으면 하나의 그룹으로 간주\n",
    "            df.loc[person_df.index, 'tracklet_id'] = tracklet_counter\n",
    "            tracklet_counter += 1\n",
    "            continue\n",
    "            \n",
    "        positions = nose_df[['x', 'y']].values\n",
    "        distances = np.linalg.norm(positions[1:] - positions[:-1], axis=1)\n",
    "        # 점프가 일어난 행의 index가 아니라, '프레임 번호'를 저장\n",
    "        jump_frames = nose_df.iloc[np.where(distances > JUMP_THRESHOLD)[0] + 1]['frame'].tolist()\n",
    "        \n",
    "        # 트랙릿의 시작과 끝 프레임 번호를 정의\n",
    "        tracklet_start_frame = person_df['frame'].min()\n",
    "        for jump_frame in jump_frames:\n",
    "            # 이전 트랙릿에 ID 할당\n",
    "            df.loc[(df['slot_id'] == slot_id) & (df['frame'] >= tracklet_start_frame) & (df['frame'] < jump_frame), 'tracklet_id'] = tracklet_counter\n",
    "            tracklet_counter += 1\n",
    "            tracklet_start_frame = jump_frame\n",
    "        \n",
    "        # 마지막 트랙릿에 ID 할당\n",
    "        df.loc[(df['slot_id'] == slot_id) & (df['frame'] >= tracklet_start_frame), 'tracklet_id'] = tracklet_counter\n",
    "        tracklet_counter += 1\n",
    "        \n",
    "    # 2. 각 트랙릿의 시작/끝 정보 수집 (이전과 동일)\n",
    "    print(\"  - 2/5: 각 트랙릿의 시작/끝 정보 수집 중...\")\n",
    "    tracklet_info = defaultdict(dict)\n",
    "    for tid, group in df.groupby('tracklet_id'):\n",
    "        start_frame_info = group.sort_values(by='frame').iloc[0]\n",
    "        end_frame_info = group.sort_values(by='frame').iloc[-1]\n",
    "        tracklet_info[tid] = {\n",
    "            'original_slot_id': start_frame_info['slot_id'], 'start_frame': start_frame_info['frame'], 'end_frame': end_frame_info['frame'],\n",
    "            'start_motion': start_frame_info[['x', 'y']].values, 'end_motion': end_frame_info[['x', 'y']].values,\n",
    "            'start_bbox': start_frame_info[['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']].values, 'end_bbox': end_frame_info[['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']].values,\n",
    "            'start_appearance': None, 'end_appearance': None\n",
    "        }\n",
    "\n",
    "    # 3. 'Single-Pass'로 외모 특징 추출 (이전과 동일)\n",
    "    print(\"  - 3/5: 비디오 단일 스캔으로 모든 외모 특징 추출 중...\")\n",
    "    features_to_extract = defaultdict(list)\n",
    "    for tid, info in tracklet_info.items():\n",
    "        if info['start_frame'] == info['end_frame']: # 단일 프레임 트랙릿 처리\n",
    "             features_to_extract[info['start_frame']].append({'tid': tid, 'role': 'single', 'bbox': info['start_bbox']})\n",
    "        else:\n",
    "            features_to_extract[info['start_frame']].append({'tid': tid, 'role': 'start', 'bbox': info['start_bbox']})\n",
    "            features_to_extract[info['end_frame']].append({'tid': tid, 'role': 'end', 'bbox': info['end_bbox']})\n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        if frame_idx in features_to_extract:\n",
    "            for item in features_to_extract[frame_idx]:\n",
    "                hist = get_color_histogram(frame, item['bbox'])\n",
    "                if hist is not None:\n",
    "                    if item['role'] == 'single':\n",
    "                        tracklet_info[item['tid']]['start_appearance'] = hist\n",
    "                        tracklet_info[item['tid']]['end_appearance'] = hist\n",
    "                    else:\n",
    "                        tracklet_info[item['tid']][f\"{item['role']}_appearance\"] = hist\n",
    "        frame_idx += 1\n",
    "    cap.release()\n",
    "    \n",
    "    # 4. 비용 행렬 계산 및 연결 그래프 생성 (이전과 동일)\n",
    "    print(\"  - 4/5: 트랙릿 간 연결 그래프 생성 중...\")\n",
    "    tids = list(tracklet_info.keys())\n",
    "    cost_matrix = np.full((len(tids), len(tids)), np.inf)\n",
    "    for i, tid1 in enumerate(tids):\n",
    "        for j, tid2 in enumerate(tids):\n",
    "            if i == j: continue\n",
    "            end_info = tracklet_info[tid1]; start_info = tracklet_info[tid2]\n",
    "            frame_gap = start_info['start_frame'] - end_info['end_frame']\n",
    "            if 0 < frame_gap < MAX_LINK_FRAMES:\n",
    "                if end_info['end_appearance'] is not None and start_info['start_appearance'] is not None:\n",
    "                    motion_cost = np.linalg.norm(end_info['end_motion'] - start_info['start_motion'])\n",
    "                    if motion_cost > DISTANCE_GATE_THRESHOLD: continue\n",
    "                    appearance_cost = 1 - cv2.compareHist(end_info['end_appearance'], start_info['start_appearance'], cv2.HISTCMP_CORREL)\n",
    "                    norm_motion_cost = min(motion_cost / DISTANCE_GATE_THRESHOLD, 1.0)\n",
    "                    total_cost = (MOTION_WEIGHT * norm_motion_cost) + (APPEARANCE_WEIGHT * appearance_cost)\n",
    "                    cost_matrix[i, j] = total_cost\n",
    "    \n",
    "    cost_matrix[np.isinf(cost_matrix)] = 1e6\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "    # 5. ID 재할당 ('가장 긴 트랙릿' 기반)\n",
    "    print(\"  - 5/5: 연결 그룹 분석 및 최종 ID 할당 중...\")\n",
    "    G = nx.Graph()\n",
    "    for r, c in zip(row_ind, col_ind):\n",
    "        if cost_matrix[r, c] < COST_THRESHOLD:\n",
    "            G.add_edge(tids[r], tids[c])\n",
    "            \n",
    "    connected_components = list(nx.connected_components(G))\n",
    "    final_id_map = {}\n",
    "    \n",
    "    for component in connected_components:\n",
    "        longest_tracklet_id = -1; max_length = -1\n",
    "        for tid in component:\n",
    "            length = tracklet_info[tid]['end_frame'] - tracklet_info[tid]['start_frame']\n",
    "            if length > max_length:\n",
    "                max_length = length; longest_tracklet_id = tid\n",
    "        if longest_tracklet_id != -1:\n",
    "            final_id = tracklet_info[longest_tracklet_id]['original_slot_id']\n",
    "            for tid in component: final_id_map[tid] = final_id\n",
    "\n",
    "    for tid in tids:\n",
    "        if tid not in final_id_map:\n",
    "            final_id_map[tid] = tracklet_info[tid]['original_slot_id']\n",
    "            \n",
    "    df['slot_id'] = df['tracklet_id'].map(final_id_map)\n",
    "    df.dropna(subset=['slot_id'], inplace=True)\n",
    "    df['slot_id'] = df['slot_id'].astype(int)\n",
    "    df.drop(columns=['tracklet_id'], inplace=True)\n",
    "    \n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"ID가 보정된 데이터가 '{output_path}'에 저장되었습니다.\")\n",
    "\n",
    "# --- 스크립트 실행 ---\n",
    "if __name__ == \"__main__\":\n",
    "    relink_switched_ids_final_corrected(INPUT_CSV_PATH, VIDEO_PATH, OUTPUT_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "106fe80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "후처리 2단계 시작: 전역적 스무딩 (최종 떨림 제거)\n",
      "  - 원본 데이터 로드 완료: 717948 행\n",
      "  - Savitzky-Golay 필터 적용 중 (window=15, polyorder=3)...\n",
      "\n",
      "후처리 2단계 완료! (총 소요 시간: 10.76초)\n",
      "미세 떨림이 제거된 최종 데이터가 'aespa_test_skeletons_smoothed.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 후처리 2-2\n",
    "# 전역적 스무딩\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- 1. 설정 및 파라미터 ---\n",
    "# 이전 단계('ID 재연결')에서 생성된 데이터 파일\n",
    "INPUT_CSV_PATH = 'aespa_test_skeletons_postprocessed.csv'\n",
    "# 최종적으로 스무딩된 데이터가 저장될 파일\n",
    "OUTPUT_CSV_PATH = 'aespa_test_skeletons_smoothed.csv'\n",
    "\n",
    "# Savitzky-Golay 필터 파라미터 (이 값들을 조정하여 스무딩 강도 조절 가능)\n",
    "# 더 강력한 스무딩을 위해 윈도우 크기를 이전보다 늘림\n",
    "WINDOW_LENGTH = 15 \n",
    "POLYORDER = 3     \n",
    "\n",
    "# --- 2. 메인 후처리 로직 ---\n",
    "def apply_global_smoothing(csv_path, output_path):\n",
    "    \"\"\"\n",
    "    ID가 보정된 데이터에 Savitzky-Golay 필터를 적용하여 미세한 떨림과 이상치를 제거합니다.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1. 파일 존재 여부 확인\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"오류: 입력 파일 '{csv_path}'를 찾을 수 없습니다. ID 재연결 단계를 먼저 실행해주세요.\")\n",
    "        return\n",
    "        \n",
    "    print(\"후처리 2단계 시작: 전역적 스무딩 (최종 떨림 제거)\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"  - 원본 데이터 로드 완료: {len(df)} 행\")\n",
    "\n",
    "    # 스무딩할 좌표 컬럼\n",
    "    coords_to_smooth = ['x', 'y', 'z']\n",
    "    \n",
    "    # 2. 각 ID, 각 관절의 이동 경로에 개별적으로 필터 적용\n",
    "    print(f\"  - Savitzky-Golay 필터 적용 중 (window={WINDOW_LENGTH}, polyorder={POLYORDER})...\")\n",
    "    \n",
    "    # 그룹별로 데이터를 처리할 때 데이터가 필터 윈도우보다 짧으면 오류가 발생할 수 있음\n",
    "    # .transform()은 이러한 그룹별 처리를 안전하고 효율적으로 수행\n",
    "    def smooth(series):\n",
    "        # 데이터가 윈도우 길이보다 짧으면 스무딩을 적용할 수 없으므로 원본을 반환\n",
    "        if len(series) < WINDOW_LENGTH:\n",
    "            return series\n",
    "        return savgol_filter(series, window_length=WINDOW_LENGTH, polyorder=POLYORDER, mode='interp')\n",
    "\n",
    "    # slot_id와 landmark_id로 그룹화하여 각 시계열(x, y, z)에 스무딩 함수 적용\n",
    "    df[coords_to_smooth] = df.groupby(['slot_id', 'landmark_id'])[coords_to_smooth].transform(smooth)\n",
    "    \n",
    "    # 3. 최종 데이터 저장\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"\\n후처리 2단계 완료! (총 소요 시간: {end_time - start_time:.2f}초)\")\n",
    "    print(f\"미세 떨림이 제거된 최종 데이터가 '{output_path}'에 저장되었습니다.\")\n",
    "\n",
    "\n",
    "# --- 3. 스크립트 실행 ---\n",
    "if __name__ == \"__main__\":\n",
    "    apply_global_smoothing(INPUT_CSV_PATH, OUTPUT_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2816348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "후처리 3단계 시작: 물리적 타당성 검증\n",
      "  - 1/3: 각 인물의 평균 신체 비율 계산 중...\n",
      "  - 2/3: 각 프레임의 물리적 오류 점수 계산 중...\n",
      "  - 3/3: 원본 데이터에 오류 점수 추가 및 저장 중...\n",
      "\n",
      "후처리 3단계 완료! (총 소요 시간: 1389.80초)\n",
      "물리적 타당성 점수가 추가된 최종 데이터가 'aespa_test_data_final_with_scores.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 후처리 3-2\n",
    "# 물리적 타당성 검증\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "# --- 1. 설정 ---\n",
    "# 이전 단계('전역적 스무딩')에서 생성된 데이터 파일\n",
    "INPUT_CSV_PATH = 'aespa_test_skeletons_smoothed.csv'\n",
    "# 최종적으로 점수가 추가된 데이터가 저장될 파일\n",
    "OUTPUT_CSV_PATH = 'aespa_test_data_final_with_scores.csv'\n",
    "\n",
    "# --- 2. 데이터 정의 ---\n",
    "BONE_MAPPING = {\n",
    "    'LEFT_ARM': (11, 13), 'RIGHT_ARM': (12, 14), 'LEFT_FOREARM': (13, 15), 'RIGHT_FOREARM': (14, 16),\n",
    "    'LEFT_UPPER_LEG': (23, 25), 'RIGHT_UPPER_LEG': (24, 26), 'LEFT_LOWER_LEG': (25, 27), 'RIGHT_LOWER_LEG': (26, 28)\n",
    "}\n",
    "\n",
    "# --- 3. 헬퍼 함수 ---\n",
    "def get_3d_distance(p1, p2):\n",
    "    return np.linalg.norm(p1 - p2)\n",
    "\n",
    "# --- 4. 메인 후처리 로직 ---\n",
    "def validate_kinematic_plausibility(csv_path, output_path):\n",
    "    \"\"\"\n",
    "    스무딩된 데이터의 물리적 타당성을 검증하고, 오류 점수를 계산하여 추가합니다.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"후처리 3단계 시작: 물리적 타당성 검증\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 분석의 편의를 위해 피벗 테이블 생성\n",
    "    df_pivot = df.pivot_table(index=['frame', 'slot_id'], columns='landmark_id', \n",
    "                              values=['x', 'y', 'z', 'visibility'])\n",
    "\n",
    "    # 1. 각 사람의 평균 '신체 비율' 계산\n",
    "    print(\"  - 1/3: 각 인물의 평균 신체 비율 계산 중...\")\n",
    "    avg_bone_ratios = defaultdict(dict)\n",
    "    for slot_id in df['slot_id'].unique():\n",
    "        person_df = df_pivot.loc[pd.IndexSlice[:, slot_id], :]\n",
    "        ratios = defaultdict(list)\n",
    "        for frame_idx in person_df.index.get_level_values('frame'):\n",
    "            try:\n",
    "                shoulder_l = person_df.loc[(frame_idx, slot_id), [('x', 11), ('y', 11), ('z', 11)]].values\n",
    "                shoulder_r = person_df.loc[(frame_idx, slot_id), [('x', 12), ('y', 12), ('z', 12)]].values\n",
    "                hip_l = person_df.loc[(frame_idx, slot_id), [('x', 23), ('y', 23), ('z', 23)]].values\n",
    "                hip_r = person_df.loc[(frame_idx, slot_id), [('x', 24), ('y', 24), ('z', 24)]].values\n",
    "                vis_shoulders = person_df.loc[(frame_idx, slot_id), [('visibility', 11), ('visibility', 12)]].values\n",
    "                vis_hips = person_df.loc[(frame_idx, slot_id), [('visibility', 23), ('visibility', 24)]].values\n",
    "                if np.all(vis_shoulders > 0.7) and np.all(vis_hips > 0.7):\n",
    "                    torso_len = get_3d_distance((shoulder_l + shoulder_r) / 2, (hip_l + hip_r) / 2)\n",
    "                    if torso_len < 10: continue\n",
    "                    for bone_name, (start_idx, end_idx) in BONE_MAPPING.items():\n",
    "                        p1_vis = person_df.loc[(frame_idx, slot_id), ('visibility', start_idx)]\n",
    "                        p2_vis = person_df.loc[(frame_idx, slot_id), ('visibility', end_idx)]\n",
    "                        if p1_vis > 0.7 and p2_vis > 0.7:\n",
    "                            p1 = person_df.loc[(frame_idx, slot_id), [('x',start_idx),('y',start_idx),('z',start_idx)]].values\n",
    "                            p2 = person_df.loc[(frame_idx, slot_id), [('x',end_idx),('y',end_idx),('z',end_idx)]].values\n",
    "                            bone_len = get_3d_distance(p1, p2)\n",
    "                            ratios[bone_name].append(bone_len / torso_len)\n",
    "            except (KeyError, IndexError): continue\n",
    "        for bone_name, ratio_list in ratios.items():\n",
    "            if ratio_list: avg_bone_ratios[slot_id][bone_name] = np.mean(ratio_list)\n",
    "\n",
    "    # 2. 각 프레임의 '운동학적 오류 점수' 계산\n",
    "    print(\"  - 2/3: 각 프레임의 물리적 오류 점수 계산 중...\")\n",
    "    error_scores = []\n",
    "    for (frame_idx, slot_id), row in df_pivot.iterrows():\n",
    "        bone_errors = []\n",
    "        try:\n",
    "            shoulder_l = row[[('x', 11), ('y', 11), ('z', 11)]].values; shoulder_r = row[[('x', 12), ('y', 12), ('z', 12)]].values\n",
    "            hip_l = row[[('x', 23), ('y', 23), ('z', 23)]].values; hip_r = row[[('x', 24), ('y', 24), ('z', 24)]].values\n",
    "            current_torso_len = get_3d_distance((shoulder_l + shoulder_r) / 2, (hip_l + hip_r) / 2)\n",
    "            if current_torso_len < 10: \n",
    "                error_scores.append({'frame': frame_idx, 'slot_id': slot_id, 'kinematic_error': 1.0}); continue\n",
    "        except (KeyError, IndexError):\n",
    "            error_scores.append({'frame': frame_idx, 'slot_id': slot_id, 'kinematic_error': 1.0}); continue\n",
    "\n",
    "        for bone_name, (start_idx, end_idx) in BONE_MAPPING.items():\n",
    "            if bone_name not in avg_bone_ratios.get(slot_id, {}): continue\n",
    "            target_ratio = avg_bone_ratios[slot_id][bone_name]\n",
    "            target_length = current_torso_len * target_ratio\n",
    "            \n",
    "            p_start = row[[('x',start_idx),('y',start_idx),('z',start_idx)]].values\n",
    "            p_end = row[[('x',end_idx),('y',end_idx),('z',end_idx)]].values\n",
    "            current_length = get_3d_distance(p_start, p_end)\n",
    "            \n",
    "            # 비율 오차 계산\n",
    "            error = abs(current_length - target_length) / (target_length + 1e-6)\n",
    "            bone_errors.append(error)\n",
    "        \n",
    "        # 해당 프레임의 모든 뼈 오차 중 가장 큰 값을 대표 오류 점수로 사용\n",
    "        frame_error = max(bone_errors) if bone_errors else 0\n",
    "        error_scores.append({'frame': frame_idx, 'slot_id': slot_id, 'kinematic_error': frame_error})\n",
    "\n",
    "    # 3. 원본 데이터에 오류 점수 추가 및 저장\n",
    "    print(\"  - 3/3: 원본 데이터에 오류 점수 추가 및 저장 중...\")\n",
    "    error_df = pd.DataFrame(error_scores)\n",
    "    final_df = pd.merge(df, error_df, on=['frame', 'slot_id'])\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"\\n후처리 3단계 완료! (총 소요 시간: {end_time - start_time:.2f}초)\")\n",
    "    print(f\"물리적 타당성 점수가 추가된 최종 데이터가 '{output_path}'에 저장되었습니다.\")\n",
    "\n",
    "# --- 스크립트 실행 ---\n",
    "if __name__ == \"__main__\":\n",
    "    validate_kinematic_plausibility(INPUT_CSV_PATH, OUTPUT_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "077ee14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시각화 시작: 최종 보정 데이터를 영상에 그립니다.\n",
      "\n",
      "시각화 완료! 최종 결과 영상이 'aespa_test_visualization_ver2.mp4'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인용 시각화 스크립트\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import random\n",
    "\n",
    "# --- 1. 설정 ---\n",
    "# 최종 보정된 데이터 파일 경로\n",
    "# ('인체 모델 제약 적용' 단계에서 생성된 최종 결과물)\n",
    "FINAL_CSV_PATH = 'TWICE_ICANTSTOPME_final_smoothed_ver2.csv'\n",
    "\n",
    "# 원본 비디오 파일 경로\n",
    "VIDEO_PATH = 'aespa_test.mp4'\n",
    "\n",
    "# 최종 결과 영상이 저장될 경로\n",
    "OUTPUT_VIDEO_PATH = 'aespa_test_visualization_ver2.mp4'\n",
    "\n",
    "# MediaPipe 관절 연결 정보 (뼈대를 그리기 위함)\n",
    "POSE_CONNECTIONS = mp.solutions.pose.POSE_CONNECTIONS\n",
    "\n",
    "# --- 2. 헬퍼 함수 ---\n",
    "def get_color_for_id(slot_id):\n",
    "    \"\"\"ID별로 일관된 색상을 생성하기 위한 간단한 함수\"\"\"\n",
    "    # ID 번호를 기반으로 색상 생성\n",
    "    random.seed(slot_id)\n",
    "    return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "# --- 3. 메인 시각화 로직 ---\n",
    "def visualize_postprocessed_skeletons(csv_path, video_path, output_path):\n",
    "    \"\"\"\n",
    "    최종 보정된 스켈레톤 데이터를 읽어 원본 영상 위에 그려,\n",
    "    결과 동영상을 생성합니다.\n",
    "    \"\"\"\n",
    "    # 1. 파일 존재 여부 확인\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"오류: 데이터 파일 '{csv_path}'를 찾을 수 없습니다.\")\n",
    "        return\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"오류: 비디오 파일 '{video_path}'를 찾을 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    print(\"시각화 시작: 최종 보정 데이터를 영상에 그립니다.\")\n",
    "    \n",
    "    # 2. 데이터 로드 및 전처리\n",
    "    # 프레임별로 데이터를 빠르게 조회하기 위해 'frame'을 인덱스로 설정\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.set_index('frame', inplace=True)\n",
    "    \n",
    "    # 3. 비디오 파일 및 결과 영상 설정\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "    frame_counter = 0\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # 4. 현재 프레임에 해당하는 스켈레톤 데이터 조회\n",
    "        try:\n",
    "            frame_data = df.loc[frame_counter]\n",
    "        except KeyError:\n",
    "            # 해당 프레임에 데이터가 없으면 원본 프레임만 저장\n",
    "            out.write(frame)\n",
    "            frame_counter += 1\n",
    "            continue\n",
    "\n",
    "        # 5. 각 ID별로 스켈레톤 그리기\n",
    "        # slot_id별로 데이터를 그룹화\n",
    "        for slot_id, group in frame_data.groupby('slot_id'):\n",
    "            landmarks = group.sort_values(by='landmark_id')\n",
    "            \n",
    "            # 랜드마크 좌표와 가시성 추출\n",
    "            points = landmarks[['x', 'y']].values\n",
    "            visibility = landmarks['visibility'].values\n",
    "            \n",
    "            color = get_color_for_id(int(slot_id))\n",
    "            \n",
    "            # 바운딩 박스 그리기\n",
    "            bbox = group.iloc[0][['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']].values\n",
    "            x1, y1, x2, y2 = [int(c) for c in bbox]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f\"ID: {int(slot_id)}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "            # 관절(점) 그리기\n",
    "            for i, point in enumerate(points):\n",
    "                if visibility[i] > 0.5:\n",
    "                    cv2.circle(frame, (int(point[0]), int(point[1])), 5, color, -1)\n",
    "            \n",
    "            # 뼈대(선) 그리기\n",
    "            for connection in POSE_CONNECTIONS:\n",
    "                start_idx, end_idx = connection\n",
    "                if visibility[start_idx] > 0.5 and visibility[end_idx] > 0.5:\n",
    "                    start_point = (int(points[start_idx, 0]), int(points[start_idx, 1]))\n",
    "                    end_point = (int(points[end_idx, 0]), int(points[end_idx, 1]))\n",
    "                    cv2.line(frame, start_point, end_point, color, 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_counter += 1\n",
    "        \n",
    "        # 실시간으로 보기 (선택사항)\n",
    "        # cv2.imshow('Final Visualization', frame)\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     break\n",
    "\n",
    "    # 6. 종료 처리\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"\\n시각화 완료! 최종 결과 영상이 '{output_path}'에 저장되었습니다.\")\n",
    "\n",
    "\n",
    "# --- 4. 스크립트 실행 ---\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_postprocessed_skeletons(FINAL_CSV_PATH, VIDEO_PATH, OUTPUT_VIDEO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562e7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV 라이브러리\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def create_gif_with_opencv(video_path, output_path, start_sec, end_sec, fps=10, resize_factor=0.5):\n",
    "    \"\"\"\n",
    "    OpenCV와 ImageIO를 사용해 동영상의 특정 구간을 GIF로 변환합니다.\n",
    "    \"\"\"\n",
    "    print(\"🆕 새로운 방법(OpenCV + ImageIO)으로 변환을 시작합니다.\")\n",
    "    try:\n",
    "        # 동영상 파일 열기\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"🚨 오류: '{video_path}' 동영상 파일을 열 수 없습니다.\")\n",
    "            return\n",
    "\n",
    "        # 동영상의 원본 FPS와 프레임 번호 계산\n",
    "        original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        start_frame = int(start_sec * original_fps)\n",
    "        end_frame = int(end_sec * original_fps)\n",
    "\n",
    "        # 변환할 프레임들을 저장할 리스트\n",
    "        frames = []\n",
    "\n",
    "        # 동영상의 특정 위치(시작 프레임)로 이동\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        \n",
    "        print(f\"🖼️ {start_frame}번 부터 {end_frame}번 프레임까지 읽는 중...\")\n",
    "        \n",
    "        current_frame = start_frame\n",
    "        while current_frame < end_frame:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break # 프레임을 더 이상 읽을 수 없으면 중단\n",
    "\n",
    "            # OpenCV는 색상 채널이 BGR 순서이므로, 일반적인 RGB 순서로 변경\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Pillow를 사용하여 이미지 크기 조절\n",
    "            pil_img = Image.fromarray(frame_rgb)\n",
    "            original_width, original_height = pil_img.size\n",
    "            new_size = (int(original_width * resize_factor), int(original_height * resize_factor))\n",
    "            \n",
    "            # Pillow 10.0.0 이후 버전을 위한 Resampling.LANCZOS 사용\n",
    "            resized_img = pil_img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "            frames.append(np.array(resized_img))\n",
    "            current_frame += 1\n",
    "\n",
    "        # 리소스 해제\n",
    "        cap.release()\n",
    "        \n",
    "        if not frames:\n",
    "            print(\"🚨 오류: 변환할 프레임을 읽지 못했습니다. 시간 설정을 확인하세요.\")\n",
    "            return\n",
    "\n",
    "        print(f\"✨ GIF 파일 생성 중... (FPS: {fps})\")\n",
    "        # ImageIO를 사용해 GIF 저장\n",
    "        imageio.mimsave(output_path, frames, fps=fps)\n",
    "        \n",
    "        print(f\"✅ 성공! GIF 파일이 다음 경로에 저장되었습니다: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 예상치 못한 오류가 발생했습니다: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f4ae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🆕 새로운 방법(OpenCV + ImageIO)으로 변환을 시작합니다.\n",
      "🖼️ 345번 부터 414번 프레임까지 읽는 중...\n",
      "✨ GIF 파일 생성 중... (FPS: 8)\n",
      "✅ 성공! GIF 파일이 다음 경로에 저장되었습니다: data/result.gif\n"
     ]
    }
   ],
   "source": [
    "# 1. 변환할 동영상 경로 (파일이 노트북과 같은 폴더에 있다면 파일명만 적어도 됩니다)\n",
    "video_path = \"data/aespa_test_visualization_ver1.mp4\"\n",
    "\n",
    "# 2. 저장할 GIF 파일명\n",
    "output_path = \"data/result.gif\"\n",
    "\n",
    "# 3. 시작 시간 (초)\n",
    "start_sec = 15\n",
    "\n",
    "# 4. 종료 시간 (초)\n",
    "end_sec = 18\n",
    "\n",
    "# 5. (선택) 초당 프레임 수 (FPS)\n",
    "fps = 8\n",
    "\n",
    "# 6. (선택) 크기 조절 비율 (0.5 = 50% 크기)\n",
    "resize_factor = 0.2\n",
    "\n",
    "# --- 위 값들을 설정한 후 아래 함수를 실행하세요 ---\n",
    "create_gif_with_opencv(video_path, output_path, start_sec, end_sec, fps, resize_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f90ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: imageio in c:\\users\\human\\.conda\\envs\\conda-venv-311\\lib\\site-packages (2.37.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\human\\.conda\\envs\\conda-venv-311\\lib\\site-packages (11.2.1)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Using cached numpy-2.2.6-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "   ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/39.0 MB 11.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 4.7/39.0 MB 11.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.1/39.0 MB 11.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.4/39.0 MB 11.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 10.7/39.0 MB 10.8 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 12.8/39.0 MB 10.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 15.5/39.0 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 17.8/39.0 MB 10.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 20.4/39.0 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.8/39.0 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.2/39.0 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.5/39.0 MB 11.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 29.1/39.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.7/39.0 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 33.0/39.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.4/39.0 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.0/39.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/39.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.0/39.0 MB 10.0 MB/s eta 0:00:00\n",
      "Using cached numpy-2.2.6-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 1.26.4\n",
      "\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "    Uninstalling numpy-1.26.4:\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   ---------------------------------------- 0/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   -------------------- ------------------- 1/2 [opencv-python]\n",
      "   ---------------------------------------- 2/2 [opencv-python]\n",
      "\n",
      "Successfully installed numpy-2.2.6 opencv-python-4.12.0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\human\\.conda\\envs\\conda-venv-311\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\human\\.conda\\envs\\conda-venv-311\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python imageio Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf6e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def clip_video_to_mp4_h264(video_path, output_path, start_sec, end_sec, fps=30, resize_factor=1.0):\n",
    "    \"\"\"\n",
    "    OpenCV를 사용해 동영상을 H.264 코덱의 MP4 파일로 저장합니다.\n",
    "    \"\"\"\n",
    "    print(\"🆕 H.264 코덱 MP4 파일로 잘라내기를 시작합니다.\")\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"🚨 오류: '{video_path}' 동영상 파일을 열 수 없습니다.\")\n",
    "            return\n",
    "\n",
    "        original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        new_width = int(original_width * resize_factor)\n",
    "        new_height = int(original_height * resize_factor)\n",
    "\n",
    "        # ▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼ 이 부분 변경 ▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼▼\n",
    "        # 가장 호환성이 좋은 H.264 코덱('avc1')을 사용하도록 설정합니다.\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
    "        # ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲\n",
    "\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (new_width, new_height))\n",
    "\n",
    "        start_frame = int(start_sec * original_fps)\n",
    "        end_frame = int(end_sec * original_fps)\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        \n",
    "        print(f\"🎞️  {start_frame}번 부터 {end_frame}번 프레임까지 처리 중...\")\n",
    "        \n",
    "        current_frame = start_frame\n",
    "        while current_frame < end_frame:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if resize_factor != 1.0:\n",
    "                resized_frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "            else:\n",
    "                resized_frame = frame\n",
    "            \n",
    "            out.write(resized_frame)\n",
    "            current_frame += 1\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        print(f\"✅ 성공! H.264 MP4 파일이 다음 경로에 저장되었습니다: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 예상치 못한 오류가 발생했습니다: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc79e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🆕 H.264 코덱 MP4 파일로 잘라내기를 시작합니다.\n",
      "🎞️  184번 부터 276번 프레임까지 처리 중...\n",
      "✅ 성공! H.264 MP4 파일이 다음 경로에 저장되었습니다: data/result_clip_2.mp4\n"
     ]
    }
   ],
   "source": [
    "# 저장할 파일명을 .mp4로 지정합니다.\n",
    "video_path = \"data/aespa_test_output.mp4\"\n",
    "output_path = \"data/result_clip.mp4\"\n",
    "\n",
    "# 10초부터 15초까지 5초 분량을 잘라냅니다.\n",
    "start_sec = 8\n",
    "end_sec = 12\n",
    "\n",
    "# 출력 동영상의 FPS와 크기 조절\n",
    "fps = 24\n",
    "resize_factor = 0.5 # 원본의 80% 크기로 약간 줄이기\n",
    "\n",
    "# MP4 생성 함수 호출\n",
    "clip_video_to_mp4_h264(video_path, output_path, start_sec, end_sec, fps, resize_factor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-venv-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
